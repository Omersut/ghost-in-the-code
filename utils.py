import git
from pathlib import Path
import yaml
import os
from typing import List, Optional, Dict
import httpx
import json
import chromadb
from chromadb.utils import embedding_functions
import torch
from sentence_transformers import SentenceTransformer
from datetime import datetime
from starlette.responses import FileResponse, StreamingResponse
import asyncio
import requests
import errno
import stat
import shutil
from fastapi import HTTPException
import markdown2
from functools import lru_cache
import time
import re

class RepoManager:
    def __init__(self, base_path: str = "repos"):
        self.base_path = Path(base_path)
        self.base_path.mkdir(exist_ok=True)
        self._active_repos = {}  # Track active repo instances

    def clone_or_pull_repo(self, repo_name: str) -> Path:
        """Repoyu klonla veya g√ºncelle"""
        try:
            # √ñnce repo baƒülantƒ±sƒ±nƒ± temizle
            if repo_name in self._active_repos:
                self._cleanup_repo(repo_name)

            # Repo bilgilerini al
            with open("repos.yaml", "r", encoding='utf-8') as f:
                config = yaml.safe_load(f)
                repo_info = next((r for r in config["repositories"] if r["name"] == repo_name), None)
                
            if not repo_info:
                raise ValueError(f"Repository {repo_name} not found in config")

            repo_path = self.base_path / repo_name
            
            if repo_path.exists():
                print(f"Pulling {repo_name}...")
                repo = git.Repo(repo_path)
                # Deƒüi≈üiklikleri geri al
                repo.git.reset('--hard')
                repo.git.clean('-fd')
                # Pull
                repo.remotes.origin.pull()
            else:
                print(f"Cloning {repo_name}...")
                repo = git.Repo.clone_from(repo_info["url"], repo_path)
                
            # Aktif repo listesine ekle
            self._active_repos[repo_name] = repo
            return repo_path

        except Exception as e:
            print(f"Error in clone_or_pull_repo: {e}")
            # Hata durumunda temizlik
            self._cleanup_repo(repo_name)
            raise

    def _cleanup_repo(self, repo_name: str):
        """Repo instance'ƒ±nƒ± temizle"""
        try:
            if repo_name in self._active_repos:
                repo = self._active_repos[repo_name]
                try:
                    repo.git.gc()  # Git garbage collection
                    repo.close()   # Git baƒülantƒ±sƒ±nƒ± kapat
                except:
                    pass
                del self._active_repos[repo_name]
        except Exception as e:
            print(f"Error cleaning up repo {repo_name}: {e}")

    def delete_repo(self, repo_name: str):
        """Repoyu sil"""
        try:
            # √ñnce repo baƒülantƒ±sƒ±nƒ± temizle
            self._cleanup_repo(repo_name)
            
            repo_path = self.base_path / repo_name
            
            if repo_path.exists():
                def handle_remove_readonly(func, path, exc):
                    if func in (os.unlink, os.rmdir) and exc[1].errno == errno.EACCES:
                        os.chmod(path, stat.S_IWRITE)
                        func(path)
                    else:
                        raise exc

                # Klas√∂r√º ve i√ßindekileri sil
                shutil.rmtree(repo_path, onerror=handle_remove_readonly)
            
            # repos.yaml'dan kaldƒ±r
            with open("repos.yaml", "r", encoding='utf-8') as f:
                config = yaml.safe_load(f)
                
            config["repositories"] = [
                r for r in config["repositories"] 
                if r["name"] != repo_name
            ]
            
            with open("repos.yaml", "w", encoding='utf-8') as f:
                yaml.dump(config, f)
                
        except Exception as e:
            print(f"Error in delete_repo: {e}")
            raise

    def pull_repo(self, repo_name: str):
        """Repoyu g√ºncelle"""
        try:
            # √ñnce repo baƒülantƒ±sƒ±nƒ± temizle
            self._cleanup_repo(repo_name)
            
            repo_path = self.base_path / repo_name
            if repo_path.exists():
                repo = git.Repo(repo_path)
                # Deƒüi≈üiklikleri geri al
                repo.git.reset('--hard')
                repo.git.clean('-fd')
                # Pull
                repo.remotes.origin.pull()
                # Aktif repo listesine ekle
                self._active_repos[repo_name] = repo
            else:
                raise Exception(f"Repo {repo_name} does not exist locally")
        except Exception as e:
            print(f"Error in pull_repo: {e}")
            raise

class ProjectAssistant:
    def __init__(self):
        self.client = chromadb.PersistentClient(path="./chroma_db")
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2",
            device=self.device
        )
        self.chat_history = {}
        self.collections = {}
        self.ollama_url = os.getenv("OLLAMA_HOST", "http://localhost:11434")
        self.max_retries = 5
        self.timeout = 60.0
        self._check_ollama_connection()
        self.current_context = {
            "type": "all",
            "repo": None,
            "files": []
        }
        # Config'i y√ºkle
        self.load_config()
        # Mevcut koleksiyonlarƒ± y√ºkle
        self._load_existing_collections()
        self._structure_cache = {}  # Dosya yapƒ±sƒ± cache'i
        self._cache_timeout = 300  # Cache timeout s√ºresi (saniye)

    def load_config(self):
        """repos.yaml dosyasƒ±ndan konfig√ºrasyonu y√ºkle"""
        try:
            with open("repos.yaml", "r", encoding="utf-8") as f:
                self.config = yaml.safe_load(f) or {}
                if "repositories" not in self.config:
                    self.config["repositories"] = []
        except FileNotFoundError:
            self.config = {"repositories": []}
        except Exception as e:
            print(f"Error loading config: {e}")
            self.config = {"repositories": []}

    def save_config(self):
        """Konfig√ºrasyonu repos.yaml'a kaydet"""
        try:
            with open("repos.yaml", "w", encoding="utf-8") as f:
                yaml.dump(self.config, f, allow_unicode=True)
        except Exception as e:
            print(f"Error saving config: {e}")
            raise

    def _check_ollama_connection(self):
        """Check if Ollama service is running"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags")
            if response.status_code != 200:
                raise Exception(f"Ollama API error: {response.status_code}")
            print("Ollama connection successful")
        except Exception as e:
            print(f"Warning: Ollama connection failed - {str(e)}")
            print("Please make sure Ollama is running with: ollama serve")

    def _normalize_collection_name(self, name: str) -> str:
        """Repo ismini ge√ßerli bir koleksiyon ismine d√∂n√º≈üt√ºr"""
        # Bo≈üluklarƒ± tire ile deƒüi≈ütir
        normalized = name.replace(' ', '-')
        # √ñzel karakterleri kaldƒ±r, sadece alfanumerik ve tire bƒ±rak
        normalized = ''.join(c for c in normalized if c.isalnum() or c == '-')
        # Birden fazla tireyi tekli tireye d√∂n√º≈üt√ºr
        normalized = '-'.join(filter(None, normalized.split('-')))
        # Ba≈üƒ±ndaki ve sonundaki tireleri kaldƒ±r
        normalized = normalized.strip('-')
        # K√º√ß√ºk harfe √ßevir
        normalized = normalized.lower()
        return normalized

    async def process_repo(self, repo_id: str, repo_path: Optional[Path] = None):
        """Process repository and create collection"""
        try:
            # Repo bilgilerini config'den al
            repo = next((r for r in self.config["repositories"] if r["name"] == repo_id), None)
            if not repo:
                raise Exception(f"Repository {repo_id} not found in config")

            # Config'deki local_path'i kullan
            if repo_path is None:
                repo_path = Path(repo["local_path"])
            
            # Process repo
            self.process_repo_content(repo_id, repo_path)
            
            # Update processed status
            repo["is_processed"] = True
            self.save_config()
            
            return {"success": True, "message": "Repository processed successfully"}
            
        except Exception as e:
            print(f"Error processing repo: {e}")
            raise

    def process_repo_content(self, repo_name: str, repo_path: Path):
        """Process repository content and create collection"""
        try:
            print(f"Processing repo: {repo_name} at {repo_path}")
            
            def update_progress(message: str):
                print(message)
                if hasattr(self, 'progress_callback'):
                    self.progress_callback(message)

            # Delete existing collection if it exists
            try:
                normalized_name = self._normalize_collection_name(repo_name)
                collection_name = f"{normalized_name}_collection"
                print(f"Checking for existing collection: {collection_name}")
                self.client.delete_collection(collection_name)
                print("Error deleting existing collection: Collection does not exist.")
            except Exception as e:
                print(f"Error deleting existing collection: {e}")

            # Create new collection
            collection = self.client.create_collection(
                name=collection_name,
                embedding_function=self.embedding_fn
            )

            # ƒ∞≈ülenmeyecek klas√∂rler
            IGNORED_DIRS = {
                # Build ve paket klas√∂rleri
                'node_modules', 'bin', 'obj', 'dist', 'build', 'target', 'packages', 'jenkins_home'
                # Versiyon kontrol ve IDE
                '.git', '.vs', '.idea', '.vscode', '__pycache__',
                # Ortam klas√∂rleri
                'venv', 'env', 'virtualenv', '.env',
                # Asset klas√∂rleri
                'assets', 'images', 'fonts', 'wwwroot', 'static', 'media',
                # Test ve d√∂k√ºmantasyon
                'test', 'tests', 'examples', 'samples',
                # Ge√ßici ve cache
                'temp', 'tmp', 'cache', 'logs'
            }

            # ƒ∞≈ülenmeyecek dosya uzantƒ±larƒ±
            IGNORED_EXTENSIONS = {
                # Binary dosyalar
                '.exe', '.dll', '.so', '.dylib',
                '.pyc', '.pyo', '.pyd',
                
                # Media dosyalarƒ±
                '.jpg', '.jpeg', '.png', '.gif', '.ico', '.svg',
                '.mp3', '.mp4', '.wav', '.avi', '.mov',
                '.pdf', '.doc', '.docx', '.xls', '.xlsx',
                
                # Sƒ±kƒ±≈ütƒ±rƒ±lmƒ±≈ü dosyalar
                '.zip', '.rar', '.7z', '.tar', '.gz', '.tgz',
                
                # Minified ve generated
                '.min.js', '.min.css',
                '.bundle.js', '.bundle.css',
                '.generated.cs', '.designer.cs',
                '.g.cs', '.g.i.cs',
                
                # Source maps ve debug
                '.map', '.pdb', '.cache',
                
                # Log ve data
                '.log', '.log.*',
                '.sqlite', '.db', '.mdf', '.ldf',
                
                # Config ve secret
                '.env',
                '.env.*',
                'appsettings.*.json',
                '*.pfx',
                '*.key',
                '*.pem',
                '*.cer',
                '*.crt',
                
                # Lock files
                'package-lock.json',
                'yarn.lock',
                'poetry.lock',
                'Pipfile.lock',
                
                # IDE ve editor
                '.suo',
                '.user',
                '.userosscache',
                '.sln.docstates',
                '.vs',
                '.vscode'
            }

            # First, analyze project structure and README
            project_info = {
                "name": repo_name,
                "path": str(repo_path),
                "readme": "",
                "description": "",
                "main_purpose": "",
                "technologies": [],
            }

            try:
                # Read and analyze README
                readme_paths = ["README.md", "README", "Readme.md", "readme.md"]
                for readme_path in readme_paths:
                    try:
                        with open(repo_path / readme_path, 'r', encoding='utf-8') as f:
                            project_info["readme"] = f.read()
                            break
                    except Exception as e:
                        print(f"Error reading README {readme_path}: {e}")
                        continue
            except Exception as e:
                print(f"Error processing README files: {e}")

            # Detect technologies based on file extensions
            tech_mapping = {
                '.py': 'Python',
                '.js': 'JavaScript',
                '.ts': 'TypeScript',
                '.jsx': 'React',
                '.tsx': 'React/TypeScript',
                '.vue': 'Vue.js',
                '.java': 'Java',
                '.cs': 'C#',
                '.go': 'Go',
                '.rb': 'Ruby',
                '.php': 'PHP',
                '.rs': 'Rust',
                '.cpp': 'C++',
                '.c': 'C',
                '.scala': 'Scala',
                '.kt': 'Kotlin',
                '.swift': 'Swift',
                '.m': 'Objective-C',
                '.html': 'HTML',
                '.css': 'CSS',
                '.scss': 'SCSS',
                '.less': 'Less',
                '.sql': 'SQL',
                'Dockerfile': 'Docker',
                'docker-compose.yml': 'Docker',
                'package.json': 'Node.js',
                'requirements.txt': 'Python',
                'pom.xml': 'Java',
                'build.gradle': 'Java',
                '.csproj': 'C#',
                'go.mod': 'Go'
            }

            technologies = set()
            for ext, tech in tech_mapping.items():
                if ext.startswith('.'):
                    if list(repo_path.rglob(f"*{ext}")):
                        technologies.add(tech)
                else:
                    if list(repo_path.rglob(ext)):
                        technologies.add(tech)

            project_info["technologies"] = list(technologies)

            # Add project overview as a special document with simple metadata
            overview_doc = f"""Project Name: {project_info['name']}
README:
{project_info['readme']}

Technologies:
{', '.join(project_info['technologies'])}
"""
            
            collection.add(
                documents=[overview_doc],
                metadatas=[{
                    "type": "project_overview",
                    "name": project_info["name"],
                    "path": project_info["path"]
                }],
                ids=[f"{repo_name}_overview"]
            )

            # Process code files
            documents = []
            metadatas = []
            ids = []
            doc_id = 0

            print("Scanning for files...")
            extensions = [
                # Web
                ".js", ".jsx", ".ts", ".tsx", ".html", ".htm", ".css", ".scss", ".less",
                # Backend
                ".cs", ".cshtml", ".vb", ".php", ".py", ".java", ".rb",
                # Config/Data
                ".json", ".xml", ".yml", ".yaml", ".ini", ".config",
                # Documentation
                ".md", ".txt", ".rst",
                # Other
                ".sql", ".sh", ".bat", ".ps1"
            ]
            
            total_files = 0
            processed_files = 0
            skipped_files = 0
            
            for ext in extensions:
                for file in repo_path.rglob(f"*{ext}"):
                    try:
                        # Klas√∂r kontrol√º
                        if any(ignored in file.parts for ignored in IGNORED_DIRS):
                            continue
                            
                        # Uzantƒ± kontrol√º
                        if any(file.name.endswith(ignored) for ignored in IGNORED_EXTENSIONS):
                            continue

                        total_files += 1
                        
                        if not any(p.startswith('.') for p in file.parts):
                            try:
                                with open(file, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    if content.strip():
                                        chunks = self._split_content(content)
                                        update_progress(f"Processing {file.relative_to(repo_path)}")
                                        processed_files += 1
                                        for i, chunk in enumerate(chunks):
                                            # Windows yollarƒ± i√ßin normalize et
                                            file_path = str(file.relative_to(repo_path)).replace('\\', '/').replace('/', '_')
                                            ids.append(f"{repo_name}_{file_path}_{i}")
                                            documents.append(chunk)
                                            metadatas.append({
                                                "file": str(file.relative_to(repo_path)),
                                                "part": i + 1,
                                                "total_parts": len(chunks)
                                            })
                                            doc_id += 1
                            except Exception as e:
                                print(f"Error processing file {file}: {e}")
                                skipped_files += 1
                                continue
                    except Exception as e:
                        print(f"Error accessing file: {e}")
                        skipped_files += 1
                        continue

            # Add documents in batches
            if documents:
                batch_size = 100
                for i in range(0, len(documents), batch_size):
                    end = min(i + batch_size, len(documents))
                    try:
                        collection.add(
                            documents=documents[i:end],
                            metadatas=metadatas[i:end],
                            ids=ids[i:end]
                        )
                    except Exception as e:
                        print(f"Error adding batch {i}-{end}: {e}")
                        continue

            self.collections[normalized_name] = collection

            # Update config with simple metadata
            try:
                for repo in self.config["repositories"]:
                    if repo["name"] == repo_name:
                        repo["is_processed"] = True
                        repo["technologies"] = list(technologies)
                        break
                self.save_config()
            except Exception as e:
                print(f"Error updating config: {e}")
                raise
            
            print(f"\nProcessing Summary:")
            print(f"Total files found: {total_files}")
            print(f"Successfully processed: {processed_files}")
            print(f"Skipped files: {skipped_files}")
            print(f"Total chunks created: {len(documents)}")

        except Exception as e:
            print(f"Error processing repository {repo_name}: {e}")
            # Hata durumunda koleksiyonu temizle
            try:
                normalized_name = self._normalize_collection_name(repo_name)
                collection_name = f"{normalized_name}_collection"
                if repo_name in self.collections:
                    self.client.delete_collection(collection_name)
                    del self.collections[repo_name]
            except:
                pass
            raise

    def _split_content(self, content: str, max_chunk_size: int = 1000) -> List[str]:
        """Split content into chunks"""
        # Dosya boyutu limitini artƒ±r
        if len(content) > 5_000_000:  # 5MB
            print(f"Skipping large file: {len(content)} bytes")
            return []
        
        # Minimum chunk boyutu
        min_chunk_size = 500

        # Kod bloƒüu ba≈ülangƒ±√ßlarƒ±nƒ± kontrol et
        def is_code_block_start(line: str) -> bool:
            patterns = [
                r'^\s*(public|private|protected)?\s*(class|interface|enum)\s+\w+',
                r'^\s*(public|private|protected)?\s*(static)?\s*\w+\s+\w+\s*\(',
                r'^\s*(function|def)\s+\w+\s*\(',
                r'^\s*namespace\s+\w+',
                # ƒ∞√ß i√ße fonksiyonlarƒ± da yakala
                r'^\s*\w+\s*=\s*function\s*\(',
                # Typescript/Javascript method tanƒ±mlarƒ±
                r'^\s*\w+\s*:\s*function\s*\(',
                r'^\s*async\s+\w+\s*\(',
                # Python decoratorlarƒ±
                r'^\s*@\w+',
            ]
            return any(re.match(pattern, line) for pattern in patterns)

        # Kod bloƒüu biti≈üini kontrol et
        def is_code_block_end(line: str, prev_lines: List[str]) -> bool:
            # Bo≈ü satƒ±r ve s√ºsl√º parantez kontrol√º
            if line.strip() == '}':
                return True
            # Python fonksiyon biti≈üi (bo≈ü satƒ±r + indent azalmasƒ±)
            if line.strip() == '' and prev_lines:
                prev_indent = len(prev_lines[-1]) - len(prev_lines[-1].lstrip())
                curr_indent = len(line) - len(line.lstrip())
                return curr_indent < prev_indent
            return False

        lines = content.split('\n')
        chunks = []
        current_chunk = []
        current_size = 0
        in_code_block = False
        context_lines = 3  # Baƒülam i√ßin √∂nceki/sonraki satƒ±r sayƒ±sƒ±
        
        for i, line in enumerate(lines):
            # Kod bloƒüu ba≈ülangƒ±cƒ±nƒ± kontrol et
            if is_code_block_start(line):
                in_code_block = True
                # √ñnceki satƒ±rlarƒ± da ekle (baƒülam i√ßin)
                if i > 0:
                    current_chunk.extend(lines[max(0, i-context_lines):i])
                    current_size += sum(len(l) for l in lines[max(0, i-context_lines):i])

            # Chunk boyutunu kontrol et
            if current_size + len(line) > max_chunk_size and not in_code_block and current_size > min_chunk_size:
                chunks.append('\n'.join(current_chunk))
                current_chunk = []
                current_size = 0

            current_chunk.append(line)
            current_size += len(line)
            
            # Kod bloƒüu biti≈üini kontrol et
            if in_code_block and is_code_block_end(line, current_chunk):
                in_code_block = False
                # Sonraki satƒ±rlarƒ± da ekle (baƒülam i√ßin)
                if i < len(lines) - 1:
                    current_chunk.extend(lines[i+1:min(len(lines), i+1+context_lines)])
                chunks.append('\n'.join(current_chunk))
                current_chunk = []
                current_size = 0

        if current_chunk:
            chunks.append('\n'.join(current_chunk))

        return chunks

    async def _query_ollama(self, prompt: str):
        """Stream response from Ollama"""
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                async with client.stream(
                    "POST",
                    f"{self.ollama_url}/api/generate",
                    json={
                        "model": "mistral",
                        "prompt": f"""You are a code analysis assistant. Your task is to answer questions about the code repository being analyzed.

IMPORTANT RULES:
1. Start by clearly stating the repository name and its main purpose
2. Keep responses focused and relevant to the question
3. Use only information from the provided code context
4. Structure responses with clear sections
5. For project overview questions:
   - State the project name first
   - Describe the main purpose
   - List key features
   - Mention technologies used
6. Use proper formatting for clarity

CONTEXT:
{prompt}

Format your response using these HTML rules:
1. Use <h2> for section titles (never use h1)
2. Use <p> for paragraphs
3. Use <ul> and <li> for lists
4. Use <code> for inline code
5. Use <pre><code> for code blocks
6. Use <blockquote> for important notes
7. Keep formatting clean and minimal
8. Do not use any decorative characters like = or -""",
                        "stream": True
                    }
                ) as response:
                    async for line in response.aiter_lines():
                        if line:
                            try:
                                data = json.loads(line)
                                if "response" in data:
                                    yield f"data: {data['response']}\n\n"
                                elif "error" in data:
                                    yield f"data: Error: {data['error']}\n\n"
                            except json.JSONDecodeError:
                                continue
        except Exception as e:
            print(f"Error in _query_ollama: {e}")
            yield f"data: Error: {str(e)}\n\n"

    async def query(self, question: str, context: Optional[dict] = None) -> dict:
        try:
            print(f"Available collections: {list(self.collections.keys())}")
            if not self.collections:
                return "Hen√ºz hi√ßbir repo eklenmemi≈ü."

            # Context bilgilerini al
            query_type = context.get("type", "all")
            repo_name = context.get("repo", "").lower()  # Repo adƒ±nƒ± k√º√ß√ºk harfe √ßevir
            files = context.get("files", [])

            print(f"Processing query - Type: {query_type}, Repo: {repo_name}")
            print(f"Question: {question}")

            try:
                if query_type == "files" and files:
                    # Dosya i√ßeriklerini doƒürudan oku
                    repo = next((r for r in self.config["repositories"] if r["name"].lower() == repo_name), None)
                    if not repo:
                        return f"Repository '{repo_name}' not found."

                    repo_path = Path(repo["local_path"])
                    file_contents = []
                    project_info = repo.get("project_info", {})

                    for file_path in files:
                        try:
                            full_path = repo_path / file_path
                            if not full_path.exists():
                                continue

                            with open(full_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                                file_contents.append(f"File: {file_path}\n\n{content}")
                        except Exception as e:
                            print(f"Error reading file {file_path}: {str(e)}")
                            continue

                    if not file_contents:
                        return "No readable files found."

                    context_text = "\n\n---\n\n".join(file_contents)
                    
                    # Prompt'u hazƒ±rla
                    prompt = f"""You are analyzing files from the project "{repo_name}".

Project Overview:
{json.dumps(project_info, indent=2)}

Files to analyze:
{context_text}

Question: {question}

Please provide a clear and well-structured answer in Turkish:
1. Start with a brief overview of how these files fit into the project
2. Break down your explanation into logical sections
3. Use bullet points or numbered lists for features
4. When showing code examples, use proper code blocks
5. Use blockquotes for important notes
6. When referencing files, use this format: `üìÑ path/to/file.ext`
7. Make sure your response aligns with the project's actual purpose and structure"""

                    return StreamingResponse(
                        self._query_ollama(prompt),
                        media_type='text/event-stream'
                    )

                else:  # repo veya all i√ßin
                    collection = self.collections.get(repo_name)
                    
                    if not collection:
                        print(f"Collection not found for repo: {repo_name}")
                        return f"Repository '{repo_name}' not found in collections."

                    try:
                        # √ñnce proje genel bilgilerini al
                        project_info = collection.get(
                            where={"type": "project_overview"},
                            include=["documents"]
                        )

                        # Sonra sorguya g√∂re ilgili i√ßeriƒüi al
                        results = collection.query(
                            query_texts=[question],
                            n_results=5,
                            include=["documents", "metadatas"]
                        )

                        if not results['documents'][0]:
                            return "Bu repo i√ßin ilgili bir bilgi bulunamadƒ±."

                        context_parts = []
                        for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
                            if metadata.get("type") != "project_overview":  # Overview'i tekrar ekleme
                                context_parts.append(f"[{metadata.get('file', 'unknown')}]\n{doc}")

                        context_text = "\n---\n".join(context_parts)

                        print(f"Found relevant content, generating response...")

                        # Prompt'u hazƒ±rla
                        if query_type == "repo":
                            prompt = f"""You are analyzing the repository "{repo_name}". Here is the project overview:

{project_info['documents'][0] if project_info['documents'] else 'No overview available'}

And here are some relevant code parts:

{context_text}

Question: {question}

Please provide a clear and well-structured answer in Turkish:
1. Make sure your response aligns with the project's actual purpose and structure
2. Break down your explanation into logical sections
3. Use bullet points or numbered lists for features
4. When showing code examples, use proper code blocks
5. Use blockquotes for important notes
6. When referencing files, use this format: `üìÑ path/to/file.ext`
7. Base your response ONLY on the actual project information provided"""
                        else:
                            prompt = f"""You are analyzing multiple repositories. Here is the relevant content:

{context_text}

Question: {question}

Please provide a clear and well-structured answer in Turkish:
1. Start with mentioning which repositories you're referencing
2. Break down your explanation into logical sections
3. Use bullet points or numbered lists for features
4. When showing code examples, use proper code blocks
5. Use blockquotes for important notes
6. When referencing files, use this format: `üìÑ path/to/file.ext`"""

                        return StreamingResponse(
                            self._query_ollama(prompt),
                            media_type='text/event-stream'
                        )

                    except Exception as e:
                        print(f"Error in query: {e}")
                        return f"Error processing query: {str(e)}"

            except Exception as e:
                print(f"Error in query: {e}")
                return f"Error processing query: {str(e)}"

        except Exception as e:
            print(f"Error: {e}")
            return str(e)

    @lru_cache(maxsize=32)
    def _get_cached_structure(self, repo_id: str, timestamp: int):
        """Get cached repository structure"""
        try:
            # Repo bilgilerini config'den al
            repo = next((r for r in self.config["repositories"] if r["name"] == repo_id), None)
            if not repo:
                raise ValueError(f"Repository {repo_id} not found")

            # Local path'i kullan
            repo_path = Path(repo["local_path"])
            if not repo_path.exists():
                raise ValueError(f"Repository path does not exist: {repo_path}")

            def create_tree(path: Path, base_path: Path):
                """Recursively create file tree"""
                try:
                    if path.is_file():
                        if path.name.startswith('.'):
                            return None
                        return {
                            "type": "file",
                            "name": path.name,
                            "path": str(path.relative_to(base_path)).replace("\\", "/")
                        }

                    if path.is_dir():
                        if path.name.startswith('.') or path.name == '.git':
                            return None

                        children = []
                        with os.scandir(path) as entries:
                            items = sorted(entries, key=lambda x: (not x.is_file(), x.name.lower()))
                            for item in items:
                                child_path = Path(item.path)
                                child_tree = create_tree(child_path, base_path)
                                if child_tree:
                                    children.append(child_tree)

                        return {
                            "type": "folder",
                            "name": path.name,
                            "path": str(path.relative_to(base_path)).replace("\\", "/"),
                            "children": children
                        }

                    return None

                except Exception as e:
                    print(f"Error processing {path}: {e}")
                    return None

            root = create_tree(repo_path, repo_path)
            if root:
                root["name"] = repo_id
            return root

        except Exception as e:
            print(f"Error getting project structure: {e}")
            raise HTTPException(status_code=404, detail="Repository not found")

    def get_repo_structure(self, repo_name: str) -> dict:
        """Get repository file structure"""
        try:
            # Cache kontrol√º
            cache_key = f"structure_{repo_name}"
            current_time = time.time()
            
            # Cache'de varsa ve s√ºresi ge√ßmediyse kullan
            if cache_key in self._structure_cache:
                cached_data = self._structure_cache[cache_key]
                if current_time - cached_data['timestamp'] < self._cache_timeout:
                    return cached_data['structure']

            repo = next((r for r in self.config["repositories"] if r["name"] == repo_name), None)
            if not repo:
                raise Exception(f"Repository {repo_name} not found")

            repo_path = Path(repo["local_path"])
            if not repo_path.exists():
                raise Exception(f"Repository path {repo_path} does not exist")

            # ƒ∞stenmeyen klas√∂rleri ve dosyalarƒ± atla
            ignored_patterns = ['.git', '__pycache__', 'node_modules', '.idea', '.vscode']
            root = {'name': repo_name, 'type': 'folder', 'children': []}

            def create_folder_structure(current_path: Path, parent: dict):
                try:
                    # Klas√∂rleri ve dosyalarƒ± sƒ±rala
                    items = sorted(current_path.iterdir(), 
                                 key=lambda x: (not x.is_dir(), x.name.lower()))
                    
                    for item in items:
                        # ƒ∞stenmeyen klas√∂rleri atla
                        if item.name in ignored_patterns:
                            continue
                            
                        # Gizli dosyalarƒ± atla
                        if item.name.startswith('.'):
                            continue
                            
                        if item.is_dir():
                            folder = {
                                'name': item.name,
                                'type': 'folder',
                                'children': []
                            }
                            parent['children'].append(folder)
                            create_folder_structure(item, folder)
                        else:
                            parent['children'].append({
                                'name': item.name,
                                'type': 'file',
                                'path': str(item.relative_to(repo_path)).replace('\\', '/')
                            })
                except Exception as e:
                    print(f"Error processing {current_path}: {e}")

            # Klas√∂r yapƒ±sƒ±nƒ± olu≈ütur
            create_folder_structure(repo_path, root)

            # Sonucu cache'le
            self._structure_cache[cache_key] = {
                'structure': root,
                'timestamp': current_time
            }

            return root

        except Exception as e:
            print(f"Error getting repo structure: {e}")
            raise

    def get_metrics(self, project_id: str):
        """Return project metrics"""
        try:
            repo = git.Repo(f"repos/{project_id}")
            return {
                "commits": len(list(repo.iter_commits())),
                "branches": len(repo.branches),
                "contributors": len(repo.git.shortlog("-s", "-n").split("\n")),
                "last_commit": repo.head.commit.committed_datetime.isoformat()
            }
        except Exception as e:
            return {"error": str(e)}

    def add_repo(self, repo_config, path=None):
        """
        Yeni bir repo ekle
        :param repo_config: Repo konfig√ºrasyonu (dict)
        :param path: Repo local path (opsiyonel)
        """
        try:
            # Eƒüer path verilmemi≈üse config'den al
            if path is None:
                path = repo_config.get("local_path")

            # Path'in ge√ßerli olduƒüunu kontrol et
            if not Path(path).exists():
                raise ValueError(f"Path does not exist: {path}")

            # Process durumunu ekle
            repo_config["is_processed"] = False

            # Repoyu ekle
            if "repositories" not in self.config:
                self.config["repositories"] = []
            
            # Aynƒ± isimli repo varsa g√ºncelle
            for i, repo in enumerate(self.config["repositories"]):
                if repo["name"] == repo_config["name"]:
                    repo_config["is_processed"] = repo.get("is_processed", False)  # Mevcut durumu koru
                    self.config["repositories"][i] = repo_config
                    break
            else:
                # Yoksa yeni ekle
                self.config["repositories"].append(repo_config)
            
            # Konfig√ºrasyonu kaydet
            self.save_config()
            
        except Exception as e:
            print(f"Error adding repo: {e}")
            raise

    def remove_repo(self, repo_name: str):
        """Repo'yu konfig√ºrasyondan kaldƒ±r"""
        try:
            self.config["repositories"] = [
                r for r in self.config["repositories"] 
                if r["name"] != repo_name
            ]
            self.save_config()
        except Exception as e:
            print(f"Error removing repo: {e}")
            raise

    def _prepare_context(self, results, files=None):
        """Prepare context from search results"""
        context_parts = []
        
        if results and results["documents"]:
            for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
                context_parts.append(f"[{meta['file']}]\n{doc}")
            
        return "\n---\n".join(context_parts)

    def list_projects(self):
        """List all available repositories"""
        try:
            projects = []
            for repo in self.config["repositories"]:
                try:
                    repo_path = Path(repo["local_path"])
                    if repo_path.exists():
                        projects.append({
                            "name": repo["name"],
                            "path": str(repo_path),
                            "is_processed": repo.get("is_processed", False)
                        })
                except Exception as e:
                    print(f"Error checking repo {repo['name']}: {e}")
                    continue
            return projects
        except Exception as e:
            print(f"Error listing projects: {e}")
            return []

    def get_file_content(self, repo_name: str, file_path: str):
        """Get file content"""
        try:
            repo = next((r for r in self.config["repositories"] if r["name"] == repo_name), None)
            if not repo:
                raise HTTPException(status_code=404, detail="Repository not found")

            full_path = Path(repo["local_path"]) / file_path
            if not full_path.exists():
                raise HTTPException(status_code=404, detail="File not found")

            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                return {
                    "content": content,
                    "language": self._detect_language(file_path),
                    "path": file_path
                }

            except UnicodeDecodeError:
                return {
                    "error": "Binary file cannot be displayed"
                }

        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
        
    def _detect_language(self, file_path: str) -> str:
        """Detect programming language from file extension"""
        ext = Path(file_path).suffix.lower()
        language_map = {
            '.js': 'javascript',
            '.jsx': 'jsx',
            '.ts': 'typescript',
            '.tsx': 'tsx',
            '.py': 'python',
            '.html': 'html',
            '.css': 'css',
            '.scss': 'scss',
            '.json': 'json',
            '.md': 'markdown',
            '.xml': 'xml',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.sh': 'bash',
            '.bash': 'bash',
            '.sql': 'sql',
            '.php': 'php',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.cs': 'csharp',
            '.go': 'go',
            '.rs': 'rust',
            '.rb': 'ruby',
            '.swift': 'swift',
            '.kt': 'kotlin',
            '.dart': 'dart',
        }
        return language_map.get(ext, 'plaintext')

    async def query_all(self, question: str):
        """Query across all repositories"""
        try:
            prompt = f"""Please provide a concise answer based on the available code:
Q: {question}"""
            
            async for chunk in self._query_ollama(prompt):
                yield chunk
            
        except Exception as e:
            yield f"Error: {str(e)}"

    async def query_repo(self, repo_id: str, question: str):
        """Query specific repository"""
        try:
            print(f"Querying repo {repo_id} with question: {question}")
            collection_name = self._normalize_collection_name(repo_id)
            print(f"Collection name: {collection_name}")
            
            # √ñnce repo'nun i≈ülenip i≈ülenmediƒüini kontrol et
            repo = next((r for r in self.config["repositories"] if r["name"] == repo_id), None)
            if not repo:
                raise Exception(f"Repository {repo_id} not found in config")
                
            if not repo.get("is_processed"):
                raise Exception(f"Repository {repo_id} has not been processed yet. Please process it first from the admin panel.")
            
            collection = self.collections.get(collection_name)
            print(f"Got collection: {collection}")
            
            results = collection.query(
                query_texts=[question],
                n_results=3,
                include=["documents", "metadatas"]
            )
            print(f"Query results: {results}")
            
            if not results['documents'][0]:
                raise Exception(f"No content found in repository {repo_id}. Try processing it again from the admin panel.")
            
            context = self._prepare_context(results)
            print(f"Prepared context: {context}")
            
            prompt = f"""Please provide a concise answer based on the code:
{context}
Q: {question}"""
            
            async for chunk in self._query_ollama(prompt):
                yield chunk
            
        except Exception as e:
            print(f"Error in query_repo: {str(e)}")
            yield f"Error: {str(e)}"

    async def query_files(self, repo_id: str, files: List[str], question: str):
        """Query specific files in a repository"""
        try:
            repo = next((r for r in self.config["repositories"] if r["name"] == repo_id), None)
            if not repo:
                raise Exception(f"Repository {repo_id} not found in config")
            
            repo_path = Path(repo["local_path"])
            print(f"Querying files in repo {repo_id}: {files}")
            
            content = []
            max_content_size = 8000  # Maksimum context boyutu
            current_size = 0
            
            for file_path in files:
                try:
                    full_path = repo_path / file_path
                    print(f"Checking file: {full_path}")
                    
                    if not full_path.exists():
                        print(f"File not found: {full_path}")
                        continue
                        
                    if not full_path.is_file():
                        print(f"Not a file: {full_path}")
                        continue
                        
                    # JSON dosyalarƒ± i√ßin √∂zel i≈üleme
                    if file_path.endswith('.json'):
                        try:
                            with open(full_path, 'r', encoding='utf-8') as f:
                                json_content = json.load(f)
                                file_content = json.dumps(json_content, indent=2)
                        except json.JSONDecodeError as je:
                            print(f"Invalid JSON in {file_path}: {je}")
                            continue
                    else:
                        # Normal text dosyalarƒ± i√ßin
                        with open(full_path, 'r', encoding='utf-8') as f:
                            file_content = f.read()

                    # Dosya √ßok b√ºy√ºkse chunk'la
                    if len(file_content) > 2000:
                        chunks = self._split_content(file_content)
                        file_content = "\n\n".join(chunks[:3])  # ƒ∞lk 3 chunk'ƒ± al
                    
                    # Context boyutunu kontrol et
                    if current_size + len(file_content) > max_content_size:
                        continue
                    
                    content.append(f"File: {file_path}\n\n{file_content}")
                    current_size += len(file_content)
                    print(f"Successfully read file: {file_path}")
                    
                except Exception as e:
                    print(f"Error reading file {file_path}: {str(e)}")
                    continue

            if not content:
                raise Exception("No readable files found")

            # Dosya i√ßeriklerini birle≈ütir
            context = "\n\n---\n\n".join(content)

            # Prompt olu≈ütur
            prompt = f"""Please analyze these files and answer the question.
For JSON files, explain the key configurations and dependencies.
For code files, explain the main functionality.

{context}

Question: {question}"""
            
            async for chunk in self._query_ollama(prompt):
                yield chunk
            
        except Exception as e:
            yield f"Error: {str(e)}"

    def get_file_history(self, project_id: str, file_path: str):
        """Dosya commit ge√ßmi≈üini getir"""
        try:
            repo_path = Path(f"repos/{project_id}")
            if not repo_path.exists():
                return {"error": "Repo bulunamadƒ±"}

            repo = git.Repo(repo_path)
            file_path = Path(file_path)
            full_path = repo_path / file_path

            if not full_path.exists():
                return {"error": "Dosya bulunamadƒ±"}

            commits = []
            try:
                # Git log komutunu kullan
                log_info = repo.git.log(
                    '--follow',  # Dosya yeniden adlandƒ±rƒ±lmƒ±≈ü olsa bile takip et
                    '--pretty=format:%H|%an|%at|%s',  # Hash|Author|Timestamp|Message
                    '--',  # Dosya yolunu belirt
                    str(file_path)
                )

                for line in log_info.split('\n'):
                    if not line.strip():
                        continue
                        
                    hash_val, author, timestamp, message = line.split('|')
                    
                    # Deƒüi≈üiklikleri al
                    try:
                        stats = repo.git.show(
                            '--numstat',
                            '--format=""',
                            hash_val,
                            '--',
                            str(file_path)
                        ).strip()
                        
                        if stats:
                            additions, deletions, _ = stats.split('\n')[0].split('\t')
                        else:
                            additions, deletions = 0, 0
                    except:
                        additions, deletions = 0, 0

                    commits.append({
                        "hash": hash_val,
                        "author": author,
                        "date": datetime.fromtimestamp(int(timestamp)).isoformat(),
                        "message": message.strip(),
                        "changes": {
                            "additions": additions,
                            "deletions": deletions
                        }
                    })

            except git.exc.GitCommandError as e:
                print(f"Git log error: {e}")
                return {"error": "Dosya ge√ßmi≈üi alƒ±namadƒ±"}

            return {
                "file": str(file_path),
                "commits": commits,
                "total_commits": len(commits)
            }
            
        except Exception as e:
            print(f"Error in get_file_history: {e}")
            return {"error": str(e)}

    def get_chat_history(self, project_id: str):
        """Proje i√ßin sohbet ge√ßmi≈üini getir"""
        try:
            return self.chat_history.get(project_id, [])
        except Exception as e:
            print(f"Error getting chat history: {e}")
            return []

    def reset_collections(self):
        """T√ºm koleksiyonlarƒ± temizle ve yeniden olu≈ütur"""
        try:
            # Mevcut koleksiyonlarƒ± listele ve sil
            collections = self.client.list_collections()
            for collection in collections:
                try:
                    self.client.delete_collection(collection.name)
                    print(f"Deleted collection: {collection.name}")
                except Exception as e:
                    print(f"Error deleting collection {collection.name}: {e}")
            
            # Koleksiyonlar s√∂zl√ºƒü√ºn√º temizle
            self.collections = {}
            print("All collections reset")
            
        except Exception as e:
            print(f"Error resetting collections: {e}")

    def list_repos(self):
        """Return list of repositories"""
        try:
            # repos.yaml dosyasƒ±ndan repo listesini al
            with open("repos.yaml", "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)
                return config.get("repositories", [])
        except Exception as e:
            print(f"Error listing repositories: {e}")
            return []

    def _load_existing_collections(self):
        """Mevcut koleksiyonlarƒ± y√ºkle"""
        try:
            # √ñnce config'deki repolarƒ± kontrol et
            print("\nChecking repositories in config:")
            for repo in self.config["repositories"]:
                print(f"- {repo['name']}: {'processed' if repo.get('is_processed') else 'not processed'}")

            # ChromaDB'den koleksiyonlarƒ± al
            collection_names = self.client.list_collections()
            print(f"\nFound collections in ChromaDB: {collection_names}")

            for name in collection_names:
                try:
                    # Koleksiyon adƒ±ndan repo adƒ±nƒ± √ßƒ±kar
                    # Koleksiyon adƒ±nƒ± normalize et
                    repo_name = name.replace('_collection', '')
                    
                    loaded_collection = self.client.get_collection(
                        name=name,
                        embedding_function=self.embedding_fn
                    )
                    # Koleksiyonlarƒ± k√º√ß√ºk harfle sakla
                    self.collections[repo_name.lower()] = loaded_collection
                    print(f"Loaded collection: {name} for repository: {repo_name}")
                except Exception as e:
                    print(f"Error loading collection {name}: {e}")

        except Exception as e:
            print(f"Error listing collections: {e}")

        print(f"\nLoaded collections: {list(self.collections.keys())}")

    def set_context(self, context_type: str, repo: str = None, files: List[str] = None):
        """UI context'ini g√ºncelle"""
        try:
            if context_type not in ["all", "repo", "files"]:
                raise ValueError("Invalid context type")
                
            self.current_context = {
                "type": context_type,
                "repo": repo,
                "files": files or []
            }
            
            return {
                "status": "success",
                "context": self.current_context,
                "message": self._get_context_message()
            }
            
        except Exception as e:
            print(f"Error setting context: {e}")
            return {
                "status": "error",
                "message": str(e)
            }

    def _get_context_message(self) -> str:
        """Mevcut context i√ßin kullanƒ±cƒ± mesajƒ± olu≈ütur"""
        if self.current_context["type"] == "all":
            return "üîç Searching across all repositories"
        elif self.current_context["type"] == "repo":
            return f"üìÅ Searching in {self.current_context['repo']}"
        else:
            files = self.current_context["files"]
            file_count = len(files)
            return f"üìÑ Searching in {file_count} selected file{'s' if file_count > 1 else ''}"

    def get_context_info(self):
        """Mevcut context bilgisini d√∂nd√ºr"""
        return {
            "current": self.current_context,
            "message": self._get_context_message(),
            "available_repos": self.list_repos(),
            "available_files": self._get_available_files() if self.current_context["repo"] else []
        }

    def _get_available_files(self):
        """Get available files for current repo"""
        if not self.current_context["repo"]:
            return []
            
        try:
            structure = self.get_repo_structure(self.current_context["repo"])
            files = []
            
            def extract_files(node):
                if node["type"] == "file":
                    files.append({
                        "path": node["path"],
                        "name": node["name"],
                        "selected": node["path"] in (self.current_context["files"] or [])
                    })
                elif node["type"] == "folder" and "children" in node:
                    for child in node["children"].values():
                        extract_files(child)
                        
            extract_files(structure)
            return files
            
        except Exception as e:
            print(f"Error getting available files: {e}")
            return []

    async def query_with_context(self, question: str):
        """Mevcut context'e g√∂re sorguyu y√∂nlendir"""
        try:
            context = self.current_context
            
            if context["type"] == "all":
                return await self.query_all(question)
            elif context["type"] == "repo" and context["repo"]:
                return await self.query_repo(context["repo"], question)
            elif context["type"] == "files" and context["files"]:
                return await self.query_files(context["repo"], context["files"], question)
            else:
                return "Please select a search context and make sure you have selected files or a repository."
                
        except Exception as e:
            return f"Error: {str(e)}"

    def get_file_encoding(self, file_path):
        """Detect file encoding"""
        try:
            import chardet
            with open(file_path, 'rb') as f:
                raw = f.read()
                result = chardet.detect(raw)
                return result['encoding']
        except:
            return "unknown"

    async def stream_response(self, prompt: str):
        """Stream the response from Ollama"""
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                async with client.stream(
                    "POST",
                    f"{self.ollama_url}/api/generate",
                    json={
                        "model": "mistral",
                        "prompt": prompt,
                        "stream": True
                    }
                ) as response:
                    async for line in response.aiter_lines():
                        if line:
                            try:
                                data = json.loads(line)
                                if "response" in data:
                                    yield f"data: {data['response']}\n\n"
                                elif "error" in data:
                                    yield f"data: Error: {data['error']}\n\n"
                            except json.JSONDecodeError:
                                continue
        except Exception as e:
            print(f"Error in stream_response: {e}")
            yield f"data: Error: {str(e)}\n\n"

class LLMAssistant:
    def __init__(self):
        self.client = chromadb.PersistentClient(path="./chroma_db")
        
        # GPU kullanƒ±mƒ±nƒ± kontrol et ve detaylƒ± log al
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"PyTorch device: {self.device}")
        
        if self.device == "cuda":
            # GPU belleƒüini temizle
            torch.cuda.empty_cache()
            # GPU'yu ƒ±sƒ±t
            self._warmup_gpu()
        
        # Model GPU'ya ta≈üƒ±
        model = SentenceTransformer("all-MiniLM-L6-v2")
        model = model.to(self.device)
        
        # Embedding fonksiyonunu GPU ile kullan
        self.embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2",
            device=self.device
        )
        
        self.collections = {}
        self._load_existing_collections()

    def _warmup_gpu(self):
        """GPU'yu ƒ±sƒ±t"""
        if self.device == "cuda":
            try:
                # K√º√ß√ºk bir model y√ºkleyerek GPU'yu hazƒ±rla
                model = torch.nn.Linear(100, 100).cuda()
                x = torch.randn(1, 100).cuda()
                for _ in range(10):
                    model(x)
                del model, x
                torch.cuda.empty_cache()
            except Exception as e:
                print(f"GPU warmup error: {e}")

    def _load_existing_collections(self):
        try:
            collection_names = self.client.list_collections()
            for name in collection_names:
                try:
                    # Koleksiyon adƒ±ndan repo adƒ±nƒ± √ßƒ±kar
                    repo_name = name.replace('_collection', '').title()
                    
                    loaded_collection = self.client.get_collection(
                        name=name,
                        embedding_function=self.embedding_fn
                    )
                    self.collections[repo_name] = loaded_collection
                    print(f"Loaded collection: {name} for repository: {repo_name}")
                except Exception as e:
                    print(f"Error loading collection {name}: {e}")

        except Exception as e:
            print(f"Error listing collections: {e}")

    def add_repo(self, name: str, path: Path):
        try:
            # √ñnce mevcut koleksiyonu temizle
            try:
                # Koleksiyonu bulmaya √ßalƒ±≈ü
                existing = self.client.get_collection(name=name)
                if existing:
                    self.client.delete_collection(name=name)
                    if name in self.collections:
                        del self.collections[name]
                    print(f"Deleted existing collection: {name}")
            except Exception as e:
                # Koleksiyon yoksa sorun deƒüil
                print(f"No existing collection found for {name}")
            
            # Yeni koleksiyon olu≈ütur
            collection = self.client.create_collection(
                name=name,
                embedding_function=self.embedding_fn
            )
            
            documents = []
            metadatas = []
            ids = []
            doc_id = 0
            
            # Dosyalarƒ± k√º√ß√ºk par√ßalara b√∂l
            for ext in [".py", ".js", ".jsx", ".ts", ".tsx", ".md"]:
                for file in path.rglob(f"*{ext}"):
                    if not any(p.startswith('.') for p in file.parts):
                        try:
                            with open(file, 'r', encoding='utf-8') as f:
                                content = f.read()
                                if content.strip():
                                    # Dosyayƒ± par√ßalara b√∂l
                                    chunks = self._split_content(content)
                                    for i, chunk in enumerate(chunks):
                                        documents.append(chunk)
                                        metadatas.append({
                                            "file": str(file.relative_to(path)),
                                            "part": i + 1,
                                            "total_parts": len(chunks)
                                        })
                                        ids.append(f"{file.stem}_chunk_{i}")
                                        doc_id += 1
                        except Exception as e:
                            print(f"Error processing {file}: {str(e)}")
                            print(f"File encoding: {self.get_file_encoding(file)}")
                            continue

            if documents:
                # Belgeleri daha k√º√ß√ºk gruplar halinde ekle
                batch_size = 100
                for i in range(0, len(documents), batch_size):
                    end = min(i + batch_size, len(documents))
                    collection.add(
                        documents=documents[i:end],
                        metadatas=metadatas[i:end],
                        ids=ids[i:end]
                    )
            
            self.collections[name] = collection
            print(f"Added repository: {name} with {len(documents)} chunks")
            
        except Exception as e:
            print(f"Error adding repository {name}: {e}")
            # Hata durumunda koleksiyonu temizle
            try:
                if name in self.collections:
                    self.client.delete_collection(name)
                    del self.collections[name]
            except:
                pass
            raise

    def _split_content(self, content: str, max_chunk_size: int = 1000) -> List[str]:
        """Split content into chunks"""
        # Dosya boyutu limitini artƒ±r
        if len(content) > 5_000_000:  # 5MB
            print(f"Skipping large file: {len(content)} bytes")
            return []
        
        # Minimum chunk boyutu
        min_chunk_size = 500

        # Kod bloƒüu ba≈ülangƒ±√ßlarƒ±nƒ± kontrol et
        def is_code_block_start(line: str) -> bool:
            patterns = [
                r'^\s*(public|private|protected)?\s*(class|interface|enum)\s+\w+',
                r'^\s*(public|private|protected)?\s*(static)?\s*\w+\s+\w+\s*\(',
                r'^\s*(function|def)\s+\w+\s*\(',
                r'^\s*namespace\s+\w+',
                # ƒ∞√ß i√ße fonksiyonlarƒ± da yakala
                r'^\s*\w+\s*=\s*function\s*\(',
                # Typescript/Javascript method tanƒ±mlarƒ±
                r'^\s*\w+\s*:\s*function\s*\(',
                r'^\s*async\s+\w+\s*\(',
                # Python decoratorlarƒ±
                r'^\s*@\w+',
            ]
            return any(re.match(pattern, line) for pattern in patterns)

        # Kod bloƒüu biti≈üini kontrol et
        def is_code_block_end(line: str, prev_lines: List[str]) -> bool:
            # Bo≈ü satƒ±r ve s√ºsl√º parantez kontrol√º
            if line.strip() == '}':
                return True
            # Python fonksiyon biti≈üi (bo≈ü satƒ±r + indent azalmasƒ±)
            if line.strip() == '' and prev_lines:
                prev_indent = len(prev_lines[-1]) - len(prev_lines[-1].lstrip())
                curr_indent = len(line) - len(line.lstrip())
                return curr_indent < prev_indent
            return False

        lines = content.split('\n')
        chunks = []
        current_chunk = []
        current_size = 0
        in_code_block = False
        context_lines = 3  # Baƒülam i√ßin √∂nceki/sonraki satƒ±r sayƒ±sƒ±
        
        for i, line in enumerate(lines):
            # Kod bloƒüu ba≈ülangƒ±cƒ±nƒ± kontrol et
            if is_code_block_start(line):
                in_code_block = True
                # √ñnceki satƒ±rlarƒ± da ekle (baƒülam i√ßin)
                if i > 0:
                    current_chunk.extend(lines[max(0, i-context_lines):i])
                    current_size += sum(len(l) for l in lines[max(0, i-context_lines):i])

            # Chunk boyutunu kontrol et
            if current_size + len(line) > max_chunk_size and not in_code_block and current_size > min_chunk_size:
                chunks.append('\n'.join(current_chunk))
                current_chunk = []
                current_size = 0

            current_chunk.append(line)
            current_size += len(line)
            
            # Kod bloƒüu biti≈üini kontrol et
            if in_code_block and is_code_block_end(line, current_chunk):
                in_code_block = False
                # Sonraki satƒ±rlarƒ± da ekle (baƒülam i√ßin)
                if i < len(lines) - 1:
                    current_chunk.extend(lines[i+1:min(len(lines), i+1+context_lines)])
                chunks.append('\n'.join(current_chunk))
                current_chunk = []
                current_size = 0

        if current_chunk:
            chunks.append('\n'.join(current_chunk))

        return chunks

    async def query(self, question: str, context: Optional[dict] = None) -> dict:
        try:
            print(f"Available collections: {list(self.collections.keys())}")
            if not self.collections:
                return "Hen√ºz hi√ßbir repo eklenmemi≈ü."

            # Context bilgilerini al
            query_type = context.get("type", "all")
            repo_name = context.get("repo", "").lower()  # Repo adƒ±nƒ± k√º√ß√ºk harfe √ßevir
            files = context.get("files", [])

            print(f"Processing query - Type: {query_type}, Repo: {repo_name}")
            print(f"Question: {question}")

            try:
                if query_type == "files" and files:
                    # Dosya i√ßeriklerini doƒürudan oku
                    repo = next((r for r in self.config["repositories"] if r["name"].lower() == repo_name), None)
                    if not repo:
                        return f"Repository '{repo_name}' not found."

                    repo_path = Path(repo["local_path"])
                    file_contents = []
                    project_info = repo.get("project_info", {})

                    for file_path in files:
                        try:
                            full_path = repo_path / file_path
                            if not full_path.exists():
                                continue

                            with open(full_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                                file_contents.append(f"File: {file_path}\n\n{content}")
                        except Exception as e:
                            print(f"Error reading file {file_path}: {str(e)}")
                            continue

                    if not file_contents:
                        return "No readable files found."

                    context_text = "\n\n---\n\n".join(file_contents)
                    
                    # Prompt'u hazƒ±rla
                    prompt = f"""You are analyzing files from the project "{repo_name}".

Project Overview:
{json.dumps(project_info, indent=2)}

Files to analyze:
{context_text}

Question: {question}

Please provide a clear and well-structured answer in Turkish:
1. Start with a brief overview of how these files fit into the project
2. Break down your explanation into logical sections
3. Use bullet points or numbered lists for features
4. When showing code examples, use proper code blocks
5. Use blockquotes for important notes
6. When referencing files, use this format: `üìÑ path/to/file.ext`
7. Make sure your response aligns with the project's actual purpose and structure"""

                    return StreamingResponse(
                        self._query_ollama(prompt),
                        media_type='text/event-stream'
                    )

                else:  # repo veya all i√ßin
                    collection = self.collections.get(repo_name)
                    
                    if not collection:
                        print(f"Collection not found for repo: {repo_name}")
                        return f"Repository '{repo_name}' not found in collections."

                    try:
                        # √ñnce proje genel bilgilerini al
                        project_info = collection.get(
                            where={"type": "project_overview"},
                            include=["documents"]
                        )

                        # Sonra sorguya g√∂re ilgili i√ßeriƒüi al
                        results = collection.query(
                            query_texts=[question],
                            n_results=5,
                            include=["documents", "metadatas"]
                        )

                        if not results['documents'][0]:
                            return "Bu repo i√ßin ilgili bir bilgi bulunamadƒ±."

                        context_parts = []
                        for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
                            if metadata.get("type") != "project_overview":  # Overview'i tekrar ekleme
                                context_parts.append(f"[{metadata.get('file', 'unknown')}]\n{doc}")

                        context_text = "\n---\n".join(context_parts)

                        print(f"Found relevant content, generating response...")

                        # Prompt'u hazƒ±rla
                        if query_type == "repo":
                            prompt = f"""You are analyzing the repository "{repo_name}". Here is the project overview:

{project_info['documents'][0] if project_info['documents'] else 'No overview available'}

And here are some relevant code parts:

{context_text}

Question: {question}

Please provide a clear and well-structured answer in Turkish:
1. Make sure your response aligns with the project's actual purpose and structure
2. Break down your explanation into logical sections
3. Use bullet points or numbered lists for features
4. When showing code examples, use proper code blocks
5. Use blockquotes for important notes
6. When referencing files, use this format: `üìÑ path/to/file.ext`
7. Base your response ONLY on the actual project information provided"""
                        else:
                            prompt = f"""You are analyzing multiple repositories. Here is the relevant content:

{context_text}

Question: {question}

Please provide a clear and well-structured answer in Turkish:
1. Start with mentioning which repositories you're referencing
2. Break down your explanation into logical sections
3. Use bullet points or numbered lists for features
4. When showing code examples, use proper code blocks
5. Use blockquotes for important notes
6. When referencing files, use this format: `üìÑ path/to/file.ext`"""

                        return StreamingResponse(
                            self._query_ollama(prompt),
                            media_type='text/event-stream'
                        )

                    except Exception as e:
                        print(f"Error in query: {e}")
                        return f"Error processing query: {str(e)}"

            except Exception as e:
                print(f"Error in query: {e}")
                return f"Error processing query: {str(e)}"

        except Exception as e:
            print(f"Error: {e}")
            return str(e)

def initialize_system():
    try:
        print("Initializing system...")
        
        # Repo konfig√ºrasyonunu y√ºkle
        with open("repos.yaml", "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
            
        # Servisleri olu≈ütur
        repo_manager = RepoManager()
        project_assistant = ProjectAssistant()

        print("\nSystem initialized - Use admin panel to manage repos")
        return project_assistant, repo_manager  # Her iki servisi de d√∂nd√ºr
        
    except Exception as e:
        print(f"Error during system initialization: {e}")
        raise 